{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "WoehbwyzqUhv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoehbwyzqUhv",
        "outputId": "3f430745-fa51-4098-f143-33bf37c72680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from np_utils) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install np_utils\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "805d42e6",
      "metadata": {
        "id": "805d42e6",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Enable eager execution\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Flatten, LeakyReLU\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Lấy dữ liệu từ bộ MNIST\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "c8cb5659",
      "metadata": {
        "id": "c8cb5659"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Tiền xử lý dữ liệu, reshape từ ảnh xám 28*28 thành vector 784 chiều và đưa dữ liệu từ scale [0, 255] về [0, 1]\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "kDcMQNt8poZw",
      "metadata": {
        "id": "kDcMQNt8poZw"
      },
      "outputs": [],
      "source": [
        "# Số chiều noise vector\n",
        "z_dim = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "aTVUIIEos-zj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTVUIIEos-zj",
        "outputId": "3f69b1b6-0e44-40eb-91a2-b1b373af28ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Optimizer\n",
        "adam = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "# Mô hình Generator\n",
        "g = Sequential()\n",
        "g.add(Dense(256, input_dim=z_dim, activation=LeakyReLU(alpha=0.2)))\n",
        "g.add(Dense(512, activation=LeakyReLU(alpha=0.2)))\n",
        "g.add(Dense(1024, activation=LeakyReLU(alpha=0.2)))\n",
        "# Vì dữ liệu ảnh MNIST đã chuẩn hóa về [0, 1] nên hàm G khi sinh ảnh ra cũng cần sinh ra ảnh có pixel value trong khoảng [0, 1] => hàm sigmoid được chọn\n",
        "g.add(Dense(784, activation='sigmoid'))\n",
        "g.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "# Mô hình Discriminator\n",
        "d = Sequential()\n",
        "d.add(Dense(1024, input_dim=784, activation=LeakyReLU(alpha=0.2)))\n",
        "d.add(Dropout(0.3))\n",
        "d.add(Dense(512, activation=LeakyReLU(alpha=0.2)))\n",
        "d.add(Dropout(0.3))\n",
        "d.add(Dense(256, activation=LeakyReLU(alpha=0.2)))\n",
        "d.add(Dropout(0.3))\n",
        "# Hàm sigmoid cho bài toán binary classification\n",
        "d.add(Dense(1, activation='sigmoid'))\n",
        "d.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "d.trainable = False\n",
        "inputs = Input(shape=(z_dim, ))\n",
        "hidden = g(inputs)\n",
        "output = d(hidden)\n",
        "gan = Model(inputs, output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "gN7OqrSntFJj",
      "metadata": {
        "id": "gN7OqrSntFJj"
      },
      "outputs": [],
      "source": [
        "# Hàm vẽ loss function\n",
        "def plot_loss(losses):\n",
        "    d_loss = [v[0] for v in losses[\"D\"]]\n",
        "    g_loss = [v[0] for v in losses[\"G\"]]\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.plot(d_loss, label=\"Discriminator loss\")\n",
        "    plt.plot(g_loss, label=\"Generator loss\")\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Hàm vẽ sample từ Generator\n",
        "def plot_generated(n_ex=10, dim=(1, 10), figsize=(12, 2)):\n",
        "    noise = np.random.normal(0, 1, size=(n_ex, z_dim))\n",
        "    generated_images = g.predict(noise)\n",
        "    generated_images = generated_images.reshape(n_ex, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MRqn-ByKwVKj",
      "metadata": {
        "id": "MRqn-ByKwVKj"
      },
      "outputs": [],
      "source": [
        "losses = {\"D\":[], \"G\":[]}\n",
        "\n",
        "def train(epochs=1, plt_frq=1, BATCH_SIZE=128):\n",
        "    # Tính số lần chạy trong mỗi epoch\n",
        "    batchCount = int(X_train.shape[0] / BATCH_SIZE)\n",
        "    print('Epochs:', epochs)\n",
        "    print('Batch size:', BATCH_SIZE)\n",
        "    print('Batches per epoch:', batchCount)\n",
        "\n",
        "    for e in tqdm(range(1, epochs+1)):\n",
        "        if e == 1 or e%plt_frq == 0:\n",
        "            print('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in range(batchCount):\n",
        "            # Lấy ngẫu nhiên các ảnh từ MNIST dataset (ảnh thật)\n",
        "            image_batch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
        "            # Sinh ra noise ngẫu nhiên\n",
        "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
        "\n",
        "            # Dùng Generator sinh ra ảnh từ noise\n",
        "            generated_images = g.predict(noise)\n",
        "            X = np.concatenate((image_batch, generated_images))\n",
        "            # Tạo label\n",
        "            y = np.zeros(2*BATCH_SIZE)\n",
        "            y[:BATCH_SIZE] = 0.9  # gán label bằng 0.9 cho những ảnh từ MNIST dataset và 0 cho ảnh sinh ra bởi Generator\n",
        "\n",
        "            # Train discriminator\n",
        "            d.trainable = True\n",
        "            d_loss = d.train_on_batch(X, y)\n",
        "\n",
        "            # Train generator\n",
        "            noise = np.random.normal(0, 1, size=(BATCH_SIZE, z_dim))\n",
        "            # Khi train Generator gán label bằng 1 cho những ảnh sinh ra bởi Generator -> cố gắng lừa Discriminator.\n",
        "            y2 = np.ones(BATCH_SIZE)\n",
        "            # Khi train Generator thì không cập nhật hệ số của Discriminator.\n",
        "            d.trainable = False\n",
        "            g_loss = gan.train_on_batch(noise, y2)\n",
        "\n",
        "        # Lưu loss function\n",
        "        losses[\"D\"].append(d_loss)\n",
        "        losses[\"G\"].append(g_loss)\n",
        "\n",
        "        # Vẽ các số được sinh ra để kiểm tra kết quả\n",
        "        if e == 1 or e%plt_frq == 0:\n",
        "            plot_generated()\n",
        "    plot_loss(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "1qVZQt3btbFq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "1qVZQt3btbFq",
        "outputId": "a516eb91-e7d1-45c1-e4e2-a8487d7ee14f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 200\n",
            "Batch size: 128\n",
            "Batches per epoch: 468\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'tqdm_notebook' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3353559938.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt_frq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2396784649.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, plt_frq, BATCH_SIZE)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Batches per epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mplt_frq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Epoch %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm_notebook' is not defined"
          ]
        }
      ],
      "source": [
        "train(epochs=200, plt_frq=20, BATCH_SIZE=128)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
