{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ed3279ab",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed3279ab",
        "outputId": "e6222fa5-4c43-4e9d-b9a5-bf0f97efe0e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: how are you\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
            "Output: khỏe không\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import CategoryEncoding # Import CategoryEncoding\n",
        "\n",
        "# 1. Dữ liệu nhỏ (English → Vietnamese)\n",
        "data = [\n",
        "    (\"hello\", \"xin chào\"),\n",
        "    (\"how are you\", \"bạn khỏe không\"),\n",
        "    (\"thank you\", \"cảm ơn bạn\"),\n",
        "    (\"good night\", \"chúc bạn ngủ ngon\"),\n",
        "    (\"see you later\", \"hẹn gặp lại\"),\n",
        "]\n",
        "\n",
        "# 2. Tách thành 2 list\n",
        "eng_texts, vi_texts = zip(*data)\n",
        "\n",
        "# 3. Tokenize mỗi ngôn ngữ\n",
        "tokenizer_eng = Tokenizer(oov_token=\"<UNK>\")\n",
        "tokenizer_eng.fit_on_texts(eng_texts)\n",
        "tokenizer_vi = Tokenizer(oov_token=\"<UNK>\")\n",
        "tokenizer_vi.fit_on_texts(vi_texts)\n",
        "\n",
        "seqs_eng = tokenizer_eng.texts_to_sequences(eng_texts)\n",
        "seqs_vi  = tokenizer_vi.texts_to_sequences(vi_texts)\n",
        "\n",
        "max_len_eng = max(len(s) for s in seqs_eng)\n",
        "max_len_vi  = max(len(s) for s in seqs_vi)\n",
        "\n",
        "seqs_eng = pad_sequences(seqs_eng, maxlen=max_len_eng, padding='post')\n",
        "seqs_vi  = pad_sequences(seqs_vi,  maxlen=max_len_vi,  padding='post')\n",
        "\n",
        "# 4. Xây mô hình Encoder-Decoder\n",
        "vocab_size_eng = len(tokenizer_eng.word_index) + 1\n",
        "vocab_size_vi  = len(tokenizer_vi.word_index)  + 1\n",
        "\n",
        "latent_dim = 64\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,), dtype='int64') # Specify dtype\n",
        "enc_emb = CategoryEncoding(num_tokens=vocab_size_eng, output_mode=\"one_hot\")(encoder_inputs) # Use CategoryEncoding\n",
        "enc_emb = Dense(latent_dim, activation='relu')(enc_emb) # Add Dense layer after one-hot encoding\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,), dtype='int64') # Specify dtype\n",
        "dec_emb = CategoryEncoding(num_tokens=vocab_size_vi, output_mode=\"one_hot\")(decoder_inputs) # Use CategoryEncoding\n",
        "dec_emb = Dense(latent_dim, activation='relu')(dec_emb) # Add Dense layer after one-hot encoding\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vocab_size_vi, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# 5. Chuẩn bị dữ liệu mục tiêu (shifted decoder input)\n",
        "decoder_target = np.zeros_like(seqs_vi)\n",
        "decoder_target[:, :-1] = seqs_vi[:, 1:]\n",
        "\n",
        "# 6. Huấn luyện\n",
        "model.fit([seqs_eng, seqs_vi], np.expand_dims(decoder_target, -1),\n",
        "          batch_size=2, epochs=300, verbose=0)\n",
        "\n",
        "# 7. Dự đoán thử\n",
        "def translate_sentence(input_sentence):\n",
        "    seq = tokenizer_eng.texts_to_sequences([input_sentence])\n",
        "    seq = pad_sequences(seq, maxlen=max_len_eng, padding='post')\n",
        "    # tạo input decoder bắt đầu (ví dụ chỉ token bắt đầu)\n",
        "    dec_seq = np.zeros((1, max_len_vi))\n",
        "    # dự đoán\n",
        "    preds = model.predict([seq, dec_seq])\n",
        "    pred_ids = np.argmax(preds[0], axis=-1)\n",
        "    words = [tokenizer_vi.index_word.get(pid, '') for pid in pred_ids]\n",
        "    return ' '.join(words).strip()\n",
        "\n",
        "print(\"Input: how are you\")\n",
        "print(\"Output:\", translate_sentence(\"how are you\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgSqlNZUOu84"
      },
      "id": "cgSqlNZUOu84",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}